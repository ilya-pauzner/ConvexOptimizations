# ConvexOptimizations

В данном проекте была поставлена задача реализовать метод 3.3 из статьи "Flexible Modification of Gauss-Newton Method" (FlexGNM)
в вариации 5.1.3, то есть, стохастический вариант. Дополнительно надо было написать этот метод с двумя видами моментов, описанных
в 5.3. Требовалось также запустить тестирование работы всех 3-ёх полученных методов оптимизации на функциях вида описанных в 4.1

В файле method_final.py находится реализация метода, в файлах method_final_momentum_armijo.py и method_final_momentum.py, 
соответственно, версии с моментами. В файле oracle.py определён базовый класс оракула, способный работать с произвольной функцией.
В func_grad_hess.py находится вспомогательная функция.

В файле testing.py определены оракулы для функций из 4.1, а также располагается код, запускающий метод с функцией из 4.1
и произвольными параметрами n и p.

Результаты тестирования приводятся в файле results.txt. Для каждого запуска указывается вид оптимизируемой функции (из 4.1), параметры
n и p, время, которое занял запуск, количество вызовов всех оракулов, количество итераций и минимальное значение нормы функции в процессе
поиска.

Детали основной функции do_method, исполняющей метод 3.3:
1. Функция принимает массив функций, где каждая функция - одна из координат функции F, размерность аргумента функции, оракула для функции f_1_cup. Дополнительно могут задаваться максимальное количество итераций, начальная точка, параметр, отвечающий за остановку поиска и массив с готовыми оракулами для функции F. 
2. Функция выполняет в лоб метод, описанный в 3.3 для случая небольших p.
3. Здесь p - параметр, соответствующий количеству градиентов, которые берутся в матрицу G.

В других файлах находятся реализации некоторых других методов, описанных в статье.
